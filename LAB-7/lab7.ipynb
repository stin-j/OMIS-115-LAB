{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "317bf65f",
   "metadata": {},
   "source": [
    "# General Preamble Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49325ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import mglearn\n",
    "from IPython.display import display\n",
    "import urllib.request\n",
    "import tarfile\n",
    "import io\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b797291b",
   "metadata": {},
   "source": [
    "# Additional code for GE Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46f248fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For GE, additional import code:\n",
    "def load_tcga_data():\n",
    "    url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/00401/TCGA-PANCAN-HiSeq-801x20531.tar.gz'\n",
    "    try:\n",
    "        with urllib.request.urlopen(url) as response:\n",
    "            with tarfile.open(fileobj=io.BytesIO(response.read()), mode=\"r:gz\") as tar:\n",
    "                data_path = 'TCGA-PANCAN-HiSeq-801x20531/data.csv'\n",
    "                labels_path = 'TCGA-PANCAN-HiSeq-801x20531/labels.csv'\n",
    "                data_file = tar.extractfile(data_path)\n",
    "                X = pd.read_csv(data_file, index_col=0)\n",
    "                labels_file = tar.extractfile(labels_path)\n",
    "                labels_df = pd.read_csv(labels_file, index_col=0)\n",
    "                y = labels_df['Class']\n",
    "                return X, y\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to download or process data. Error: {e}\")\n",
    "        return None, None\n",
    "X, y = load_tcga_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51a7407a",
   "metadata": {},
   "source": [
    "# Question 1\n",
    "- Standardize the training and test sets using StandardScaler into (X_train_scaled). How many samples are there in your training dataset?\n",
    "- Train a KNeighborsClassifier (n_neighbors=5) on the standardized, full-dimensional training data. Report the model's accuracy on the standardized test set. Also use the %%time magic command to measure and report the total time it takes to fit the model and make predictions.\n",
    "- Now, do the above step and train 2 additional KNNs on only the first 300 samples, and the first 450 samples in the datasets. Plot the accuracy and time taken with 300, 450, and 600 on the x-axis and the corresponding values of time and accuracy on the y-axis.\n",
    "- Does this plot allow you to guesstimate the time and accuracy when there are 50,000 patients in the dataset? What challenges does a distance-based algorithm like KNN still face on a scaled, but very high-dimensional, dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa67173b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"############ Assignment 7 Question 1 BEGIN ############\")\n",
    "# part a\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.75, random_state=0, stratify=y)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "print(f\"Number of samples in training dataset: {X_train.shape[0]}\")\n",
    "\n",
    "# part b\n",
    "knn_full = KNeighborsClassifier(n_neighbors=5)\n",
    "knn_full.fit(X_train_scaled, y_train)\n",
    "y_pred_full = knn_full.predict(X_test_scaled)\n",
    "print(f\"Accuracy on standardized test set: {accuracy_score(y_test, y_pred_full):.4f}\")\n",
    "\n",
    "# part c\n",
    "sample_sizes = [300, 450, 600]\n",
    "accuracies = []\n",
    "times = []\n",
    "\n",
    "for n in sample_sizes:\n",
    "    X_train_n = X_train_scaled[:n]\n",
    "    y_train_n = y_train.iloc[:n]\n",
    "    start = time.time()\n",
    "    knn = KNeighborsClassifier(n_neighbors=5)\n",
    "    knn.fit(X_train_n, y_train_n)\n",
    "    y_pred = knn.predict(X_test_scaled)\n",
    "    elapsed = time.time() - start\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    accuracies.append(acc)\n",
    "    times.append(elapsed)\n",
    "    print(f\"Accuracy {n} samples: {acc:.4f}, Time: {elapsed:.2f}s\")\n",
    "\n",
    "# Plot accuracy and time\n",
    "fig, ax1 = plt.subplots()\n",
    "color = 'tab:blue'\n",
    "ax1.set_xlabel('Training Samples')\n",
    "ax1.set_ylabel('Accuracy', color=color)\n",
    "ax1.plot(sample_sizes, accuracies, marker='o', color=color)\n",
    "ax1.tick_params(axis='y', labelcolor=color)\n",
    "\n",
    "ax2 = ax1.twinx()\n",
    "color = 'tab:red'\n",
    "ax2.set_ylabel('Time (second)', color=color)\n",
    "ax2.plot(sample_sizes, times, marker='o', color=color)\n",
    "ax2.tick_params(axis='y', labelcolor=color)\n",
    "\n",
    "plt.title('KNN: Training Size vs. Accuracy + Time')\n",
    "plt.show()\n",
    "\n",
    "# part d\n",
    "print(\"While we could extrapolate the model training time is flattening out and will be around 0.5 seconds, the trend for model accuracy as train set size increases is less clear.\")\n",
    "print(\"This is because KNN faces challenges in high dimensions due to the curse of dimensionality, making distance less meaningful and computation expensive even with scaling. Especially with 50,000 patients, time and memory requirements would grow rapidly exponentially.\")\n",
    "print(\"############# Assignment 7 Question 1 END #############\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c195530f",
   "metadata": {},
   "source": [
    "# Question 2\n",
    "- Fit an instance of PCA on the standardized training data (X_train_scaled). Do not specify the number of components yet.\n",
    "- Generate a \"scree plot\" by creating a bar chart of the explained_variance_ratio_ for the first 50 principal components. \n",
    "- Generate a cumulative explained variance plot for at least 500 components. On the same plot, add a horizontal line at y=0.90 to represent the 90% threshold.\n",
    "- Based on your cumulative plot, approximately how many principal components are required to capture 90% of the total variance?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24ad9b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"############ Assignment 7 Question 2 BEGIN ############\")\n",
    "\n",
    "pca = PCA()\n",
    "pca.fit(X_train_scaled)\n",
    "\n",
    "explained_variance_ratio = pca.explained_variance_ratio_\n",
    "\n",
    "n_components_to_plot = 50\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.bar(range(1, n_components_to_plot + 1), explained_variance_ratio[:n_components_to_plot], label=\"Individual Explained Variance Ratio\")\n",
    "plt.title(f\"Screen Plot\")\n",
    "plt.xlabel(\"Principal Component Index\")\n",
    "plt.ylabel(\"Explained Variance Ratio\")\n",
    "plt.grid(axis=\"y\", linestyle=\"--\")\n",
    "plt.xticks(range(0, n_components_to_plot + 1, 5))\n",
    "plt.show()\n",
    "\n",
    "n_components_to_plot = 500\n",
    "\n",
    "cumulative_variance = np.cumsum(explained_variance_ratio)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(range(1, n_components_to_plot + 1), cumulative_variance[:n_components_to_plot], marker=\"o\", linestyle=\"--\",label=\"Cumulative Explained Variance\")\n",
    "\n",
    "threshold = 0.90\n",
    "plt.axhline(y=threshold, linestyle=\"-\", linewidth=2,label=f\"{threshold*100:.0f}% Threshold\")\n",
    "\n",
    "n_components_90 = np.argmax(cumulative_variance >= threshold) + 1\n",
    "\n",
    "plt.axvline(x=n_components_90, linestyle=\":\",label=f\"Components for {threshold*100:.0f}%\",)\n",
    "    \n",
    "plt.title(f\"Cumulative Explained Variance for First {n_components_to_plot} PCs\")\n",
    "plt.xlabel(\"Number of Principal Components\")\n",
    "plt.ylabel(\"Cumulative Explained Variance\")\n",
    "plt.legend(loc=\"best\")\n",
    "plt.grid(True, linestyle=\"--\")\n",
    "plt.xticks(range(0, n_components_to_plot + 1, 5))\n",
    "plt.ylim(0, 1.05)\n",
    "plt.show()\n",
    "\n",
    "print(f\"Approximately {n_components_90} principal components are required to capture 90% of the total variance.\")\n",
    "\n",
    "print(\"############# Assignment 7 Question 2 END #############\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56080adb",
   "metadata": {},
   "source": [
    "# Question 3\n",
    "- Use the PCA model from Question 2 create the following 2D scatter plot. Color each point in the scatter plot according to its true cancer type (y_test). \n",
    "    - X-axis is PC1, y-axis PC2\n",
    "    - X-axis is PC1, y-axis PC3 \n",
    "    - X-axis PC2, y-axis PC3\n",
    "    - X-axis PC1, y-axis PC4\n",
    "- Based on your plots, how well does each combination of principal components separate the different cancer types? Why would it be impossible to create such an informative plot using any two of the original 20,000+ genes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b384bc33",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"############ Assignment 7 Question 3 BEGIN ############\")\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "encoder = LabelEncoder()\n",
    "colors = encoder.fit_transform(y_test)\n",
    "\n",
    "#Part A\n",
    "X_pca = pca.transform(X_test_scaled)\n",
    "\n",
    "plot_pairs = [\n",
    "    (0, 1, 'PC1 vs PC2'),\n",
    "    (0, 2, 'PC1 vs PC3'),\n",
    "    (1, 2, 'PC2 vs PC3'),\n",
    "    (0, 3, 'PC1 vs PC4')\n",
    "]\n",
    "\n",
    "for i, j, title in plot_pairs:\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    \n",
    "    scatter = plt.scatter(\n",
    "        X_pca[:, i], # Select the X-axis PC\n",
    "        X_pca[:, j], # Select the Y-axis PC\n",
    "        c=colors,\n",
    "        cmap='Accent'\n",
    "    )\n",
    "\n",
    "    legend_handles = []\n",
    "    for idx, label in enumerate(encoder.classes_):\n",
    "        legend_handles.append(plt.scatter([], [], marker='o', color=scatter.cmap(scatter.norm(idx)), label=label))\n",
    "    plt.legend(handles=legend_handles, title=\"Cancer Type\")\n",
    "\n",
    "    plt.xlabel(f'Principal Component {i+1}')\n",
    "    plt.ylabel(f'Principal Component {j+1}')\n",
    "    plt.title(f'PCA Scatter Plot: {title}')\n",
    "    plt.show()\n",
    "\n",
    "#Part B\n",
    "print(\"Each pair of principal components does somewhat okay at separating the different cancer types, usually able to isolate 2 types while the remaining 3 are overlapping.\")\n",
    "print(\"It's impossible to create as informative of a plot using pairs of the original genes because it's unlikely any random pair will truly capture the distinguishing features of each cancer type since they usually each rely on multiple different genes to be expressed.\")\n",
    "\n",
    "print(\"############# Assignment 7 Question 3 END #############\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99dfb541",
   "metadata": {},
   "source": [
    "# Question 4\n",
    "- Create a new PCA instance, setting n_components to the number you identified in Question 2d to capture 90% of the variance. Fit this new PCA on the standardized training data and use it to transform both the training and test sets.\n",
    "- Train the same KNeighborsClassifier from Question 1 on this new, lower-dimensional PCA-transformed training data again for 300, 450, and 600 samples.\n",
    "- Report the accuracy and use %%time to report the total time for fitting and prediction and compare the accuracy and total time of this model to your baseline model in Question and draw the same plot relative to different sample sizes.\n",
    "- What does this \"apples-to-apples\" comparison tell you about the specific advantages of PCA for an algorithm like KNN, especially if extrapolated to a situation where we might have 50,000 patients in the data?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80add701",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"############ Assignment 7 Question 4 BEGIN ############\")\n",
    "\n",
    "#Part A\n",
    "pca_q4 = PCA(n_components=n_components_90)\n",
    "pca_q4.fit(X_train_scaled)\n",
    "X_train_pca = pca_q4.transform(X_train_scaled)\n",
    "X_test_pca = pca_q4.transform(X_test_scaled)\n",
    "\n",
    "#Part B\n",
    "sample_sizes = [300, 450, 600]\n",
    "accuracies_q4 = []\n",
    "times_q4 = []\n",
    "\n",
    "print(\"KNN with PCA\")\n",
    "for n in sample_sizes:\n",
    "    X_train_n = X_train_pca[:n]\n",
    "    y_train_n = y_train.iloc[:n]\n",
    "    start_q4 = time.time()\n",
    "    knn_q4 = KNeighborsClassifier(n_neighbors=5)\n",
    "    knn_q4.fit(X_train_n, y_train_n)\n",
    "    y_pred_q4 = knn_q4.predict(X_test_pca)\n",
    "    elapsed_q4 = time.time() - start\n",
    "    acc_q4 = accuracy_score(y_test, y_pred_q4)\n",
    "    accuracies_q4.append(acc_q4)\n",
    "    times_q4.append(elapsed_q4)\n",
    "#Part C (WIP; are these numbers correct? I'm not sure these are the results we should be getting)\n",
    "    print(f\"Accuracy {n} samples: {acc_q4:.4f}, Time: {elapsed_q4:.2f}s\")\n",
    "\n",
    "#compare with question 2's model:\n",
    "print(\"\\nKNN without PCA:\")\n",
    "for n in range(len(accuracies)):\n",
    "    print(f\"Accuracy {sample_sizes[n]} samples: {accuracies[n]:.4f}, Time: {times[n]:.4f}\")\n",
    "\n",
    "# Plot accuracy and time\n",
    "fig, ax1 = plt.subplots()\n",
    "color = 'tab:blue'\n",
    "ax1.set_xlabel('Training Samples')\n",
    "ax1.set_ylabel('Accuracy', color=color)\n",
    "ax1.plot(sample_sizes, accuracies_q4, marker='o', color=color)\n",
    "ax1.tick_params(axis='y', labelcolor=color)\n",
    "\n",
    "ax2 = ax1.twinx()\n",
    "color = 'tab:red'\n",
    "ax2.set_ylabel('Time (second)', color=color)\n",
    "ax2.plot(sample_sizes, times_q4, marker='o', color=color)\n",
    "ax2.tick_params(axis='y', labelcolor=color)\n",
    "\n",
    "plt.title('KNN w/ PCA: Training Size vs. Accuracy + Time')\n",
    "plt.show()\n",
    "\n",
    "#Part D (WIP)\n",
    "print(\"This comparison tells us that a specific advantage of PCA for an algorithm like KNN is...\"\n",
    "\n",
    "print(\"############# Assignment 7 Question 4 END #############\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2998d2c6",
   "metadata": {},
   "source": [
    "# Question 5\n",
    "- Extract the loadings for the first principal component (PC1) from the components_ attribute of the PCA model fit in Question 2. \n",
    "- Find the top 10 genes with the largest absolute loading values and report their loading values. \n",
    "- Create a horizontal bar chart to visualize the loadings of these top 10 genes. \n",
    "- In a biological context, what does it mean for these specific genes to have high loading values on the first principal component? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed7a5c0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"############ Assignment 7 Question 5 BEGIN ############\")\n",
    "\n",
    "print(\"############# Assignment 7 Question 5 END #############\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edd3904c",
   "metadata": {},
   "source": [
    "# Question 6\n",
    "- Use the PCA model from Question 4 (explaining 90% variance) to inverse_ transform your X_train_pca data back to the ~20k dimensions. Calculate the Mean Squared Error (MSE) between the original X_train_scaled and this new reconstructed data. What does this error represent?\n",
    "- To visualize this, create a line plot showing the expression levels of the first 200 genes for the first patient in the original X_train_scaled data. On the same plot, show the expression levels for the same patient from the reconstructed data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57aee20c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"############ Assignment 7 Question 6 BEGIN ############\")\n",
    "\n",
    "print(\"############# Assignment 7 Question 6 END #############\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "455defc2",
   "metadata": {},
   "source": [
    "# Question 7\n",
    "- The Necessity of Scaling for PCA Explain, with reference to how PCA's algorithm is based on maximizing variance, why failing to scale features like gene expression levels would lead to a meaningless result. How does this differ from decision trees?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "837afe4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"############ Assignment 7 Question 7 BEGIN ############\")\n",
    "print(\"Since PCA's algorithm is based on maximizing variance, failing to scale features will mean that features with larger ranges of possible values will have a greater degree of variance, leading to PCA overprioritizing some features over others due to their scale rather than actual importance.\")\n",
    "print(\"This differs from decision trees which make splitting decisions per feature and thus don't require scaling.\")\n",
    "print(\"############# Assignment 7 Question 7 END #############\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5da2347e",
   "metadata": {},
   "source": [
    "# Question 8\n",
    "- Interpretability: Like question 5b, now write out the top 10 genes of the first 5 principal components trained in Question 2 and their corresponding loading values. If youâ€™re a data scientist with no biological background, and you are asked to explain the meaning of each of the principal components would you be able to explain it? How might a biologist use their expertise to explain each principal component better?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adbed7ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"############ Assignment 7 Question 8 BEGIN ############\")\n",
    "#write out the top 10 genes of the first 5 principal components from Q2 (WIP)\n",
    "print(\"As someone without a biological background, the meaning of each principal component would be difficult to explain since its just capturing the vectors/PCs that capture the most variance.\")\n",
    "print(\"What each PC means because there is no latent label or meaning, it's a mathematical construct of orthogonal axes. However, a biologist might understand from the loadings of each PC what meaning is being derived from the original features.\")\n",
    "print(\"For example, a PC might have high loading values for a group of features that are related to a particular symptom and therefore the model uses that PC to classify cancer types that exhibit those symptoms.\"\n",
    "print(\"############# Assignment 7 Question 8 END #############\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73edffbc",
   "metadata": {},
   "source": [
    "# Question 9\n",
    "- Bioinformatics: This lab demonstrates a standard bioinformatics workflow: scaling -> PCA -> algorithmic processing. Explain why this approach is so powerful for finding meaningful patterns in massive genomic datasets and its importance for cancer research."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65bf2790",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"############ Assignment 7 Question 9 BEGIN ############\")\n",
    "print(\"This bioinformatics approach towards fining meaningul patterns in massive datasets is powerful and important because it allows us to analyze high dimensionality datasets more easily and effectively. Trying to manually look at 10,000 genes for 10,000 patients to determine their cancer type is unfeasible and will be more error-prone than using algorithms like PCA to streamline the analysis. \")\n",
    "print(\"############# Assignment 7 Question 9 END #############\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
